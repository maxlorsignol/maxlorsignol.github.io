# Define input raster files (replace with actual file paths)
raster_files = {
"biological_sensitivity": "path/to/biological_sensitivity.tif",
"watershed": "path/to/watershed.tif",
"streams": "path/to/streams.tif",
"wetlands": "path/to/wetlands.tif",
"slope": "path/to/slope.tif",
"buffer_protected": "path/to/buffer_protected.tif",
"forest_age": "path/to/forest_age.tif"
}
# Define weights (should sum to 1)
weights = {
"biological_sensitivity": 0.2,
"watershed": 0.15,
"streams": 0.15,
"wetlands": 0.1,
"slope": 0.1,
"buffer_protected": 0.15,
"forest_age": 0.15
}
# Read rasters and apply weights
weighted_sum = None
for layer, path in raster_files.items():
with rasterio.open(path) as src:
raster_data = src.read(1).astype(float)  # Read raster band 1
raster_data[raster_data == src.nodata] = np.nan  # Handle NoData values
if weighted_sum is None:
weighted_sum = weights[layer] * raster_data
else:
weighted_sum += weights[layer] * raster_data
import rasterio
import numpy as np
import geopandas as gpd
import matplotlib.pyplot as plt
from rasterio.plot import show
from rasterio.mask import mask
# Define input raster files (replace with actual file paths)
raster_files = {
"biological_sensitivity": "path/to/biological_sensitivity.tif",
"watershed": "path/to/watershed.tif",
"streams": "path/to/streams.tif",
"wetlands": "path/to/wetlands.tif",
"slope": "path/to/slope.tif",
"buffer_protected": "path/to/buffer_protected.tif",
"forest_age": "path/to/forest_age.tif"
}
# Define weights (should sum to 1)
weights = {
"biological_sensitivity": 0.2,
"watershed": 0.15,
"streams": 0.15,
"wetlands": 0.1,
"slope": 0.1,
"buffer_protected": 0.15,
"forest_age": 0.15
}
# Read rasters and apply weights
weighted_sum = None
for layer, path in raster_files.items():
with rasterio.open(path) as src:
raster_data = src.read(1).astype(float)  # Read raster band 1
raster_data[raster_data == src.nodata] = np.nan  # Handle NoData values
if weighted_sum is None:
weighted_sum = weights[layer] * raster_data
else:
weighted_sum += weights[layer] * raster_data
# Normalize weighted sum (optional)
weighted_sum = (weighted_sum - np.nanmin(weighted_sum)) / (np.nanmax(weighted_sum) - np.nanmin(weighted_sum))
# Load parcel data (replace with actual file path)
parcels = gpd.read_file("path/to/parcels.shp")
# Select top X% parcels based on suitability (e.g., top 10%)
threshold = np.nanpercentile(weighted_sum, 90)  # Adjust percentage as needed
selected_parcels = parcels.copy()
selected_parcels["suitability"] = selected_parcels.geometry.centroid.apply(
lambda pt: weighted_sum[int(pt.y), int(pt.x)] if weighted_sum[int(pt.y), int(pt.x)] >= threshold else np.nan
)
selected_parcels = selected_parcels.dropna()
# Plot results
fig, ax = plt.subplots(figsize=(10, 8))
show(weighted_sum, cmap="viridis", title="Weighted Suitability Map", ax=ax)
parcels.boundary.plot(ax=ax, edgecolor='gray', linewidth=0.5)
selected_parcels.boundary.plot(ax=ax, edgecolor='red', linewidth=1.5, label="Selected Parcels")
plt.legend()
plt.show()
quarto check jupyter
reticulate::repl_python()
# install.packages("tidyverse")
# install.packages("sf")
# install.packages("here")
# install.packages("readxl")
# install.packages("units")
# install.packages("RColorBrewer")
# install.packages("terra")
# install.packages("gstat")
# install.packages("sp")
# install.packages("tmap")
library(tidyverse)
library(sf)
library(here)
library(readxl)
library(units)
library(RColorBrewer)
library(terra)
#Set up CRS
TARGET_CRS <- 32610
#Re-project both datasets to WGS 84 / UTM zone 10N CRS
neighborhoods <- st_read(here("data/van_local_areas.geojson")) %>%
st_transform(TARGET_CRS)%>%
mutate(neighb_area_m_sqrd = drop_units(st_area(.))) %>%
rename(area_name = name)
#Read municipal parks
parks <- st_read(here("data/van_parks.geojson")) %>%
select(park_name) %>%
st_transform(TARGET_CRS)
#Read regional parks and join with municipal parks
pacific_spirit <- st_read(here("data/metro_van_regional_parks.geojson")) %>%
rename(park_name = parkname) %>%
select(park_name) %>%
filter(park_name == "Pacific Spirit Regional Park") %>%
st_transform(TARGET_CRS)
#Add pacific spirit to parks
parks <- rbind(parks, pacific_spirit)
plot(st_geometry(parks),
col = "#228B22",
main = "Parks of Vancouver")
plot(neighborhoods$geometry, add = T)
plot(st_geometry(pacific_spirit), add = T, col = "lightgreen")
df <- read_xlsx(here("data/van_census.xlsx"))
#Set unique IDs of census variables we want to include
var_ids_to_include<- c(
17,   # Total - Age 65 years and older - 100% data
3966, # Median after-tax income of households in 2015 ($)
1013, # unemployment rate
1018  # Non-official languages
)
#Pre-processing pipeline for census data
df <- df %>%
#Subset df to target variables only (can search based on ID in excel spreadsheet)
filter(ID %in% var_ids_to_include) %>%
select(-ID) %>%
#Convert df to format where each row is a neighborhood
pivot_longer(cols = -Variable, names_to = "area", values_to = "Value") %>%
pivot_wider(names_from = "Variable", values_from = "Value") %>%
#Calculate percentage of non-native speakers variable
mutate(perc_non_native = `Non-official languages` / `Total - Language spoken most often at home for the total population excluding institutional residents - 100% data` * 100) %>%
#Rename columns using shorter names
rename(
median_income = `Median after-tax income of households in 2015 ($)`,
total_population = `Total - Age groups and average age of the population - 100% data`
) %>%
#Select the variables we want to keep
select(area, median_income, perc_non_native, total_population) %>%
#Fix arbutus ridge name
mutate(area = if_else(area == "Arbutus-Ridge", "Arbutus Ridge", area))
df <- read_xlsx(here("data/van_census.xlsx"))
#Set unique IDs of census variables we want to include
var_ids_to_include<- c(
17,   # Total - Age 65 years and older - 100% data
3966, # Median after-tax income of households in 2015 ($)
1013, # unemployment rate
1018  # Non-official languages
)
#Pre-processing pipeline for census data
df <- df %>%
#Subset df to target variables only (can search based on ID in excel spreadsheet)
filter(ID %in% var_ids_to_include) %>%
select(-ID) %>%
#Convert df to format where each row is a neighborhood
pivot_longer(cols = -Variable, names_to = "area", values_to = "Value") %>%
pivot_wider(names_from = "Variable", values_from = "Value") %>%
#Calculate percentage of non-native speakers variable
mutate(perc_non_native = `Non-official languages` / `Total - Language spoken most often at home for the total population excluding institutional residents - 100% data` * 100) %>%
#Rename columns using shorter names
rename(
median_income = "Median after-tax income of households in 2015 ($)",
total_population = "Total - Age groups and average age of the population - 100% data"
) %>%
#Select the variables we want to keep
select(area, median_income, perc_non_native, total_population) %>%
#Fix arbutus ridge name
mutate(area = if_else(area == "Arbutus-Ridge", "Arbutus Ridge", area))
